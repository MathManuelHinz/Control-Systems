\chapter{Control Problems}

\begin{enumerate}
    \item $u$ is the  \dhighlight{control (input / action)}
    \item $y$ observations (outputs)
    \item $\phi:Y\to U$ policy
    \item $\text{ff}$ feed forward control (plan we had)
\end{enumerate}

Interactions with the outside world might be hidden in the observations. Typically $\ff$ is 
in regard to some reference state. There might be some disturbances (holes in the road, \dots).

The overall aim is to find a policy \(\phi\) that sticks close to $r(k),k\geq 0$ \marginnote{$t$ is continous, $k$ is step by step / iterative}.
\[u(k)=u_\ff(k)+U_{fb}(k)\]
where $u_\ff$ is the planing to reach the overall goal and $u_{\fb}$ actual steering, updated "all the time".

Some examples from the book:

\begin{figure}[H]\label{fig:1.01}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
    \caption{Sketch 1.01}
\end{figure}

\begin{figure}[H]\label{fig:1.02}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
    \caption{Sketch 1.02: Mountain car}
\end{figure}

Difference: In Reinforcement learning, we don't start with a model / ode. 

Some part of reinforcement learning works model-free (i.e. assumes the model only implicitly)

\begin{figure}[H]\label{fig:1.03}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
    \caption{Sketch 1.03: cart pole / inverted pendulum}
\end{figure}

Next example: Acrobot (more then one equilibrium)

\section{State Space Models}

We have some

\begin{itemize}
    \item \dhighlight{state space} \(X,x\in X\)
    \item \dhighlight{action space} \(U, u\in U\)
    \item \dhighlight{action} at step \(k: u(k)\in U(k)\), i.e. we might have some constraints
    \item \dhighlight{observation space \(Y,y\in Y\)}
\end{itemize}

\begin{definition}\label{def:1,1} \marginnote{\(x(k)\) might include the past, might be useful for the stock trading problem}
    Given state, action and observation spaces \(X,U,Y\), a \dhighlight{state space model}
    is defined by
    \begin{align}\label{eq:1}
        x(k+1)&=\cF(x(k),u(k))\\
        y(k)&=\mathcal{C}(x(k),u(k))  
    \end{align}
\end{definition}

\begin{remark}
    Overcomplicating problems by loading lots of information into the state space, might make the problem harder!
\end{remark}

\subsection{Linear State Space Model}

\begin{align}\label{eq:lssm}
    x(k+1)&=Fx(k)+Gu(k)\\
    y(k)&=Cx(k)+Du(k)
\end{align}

\begin{remark}
    The representations (in terms of the matrices) might not be unique!
\end{remark}

Common scenario for (\ref{eq:lssm}) is to keep \(x(k)\) near the origin. You have to think about robustness of the system. 
Disturbances should be handled by the system. 

\begin{align*}
    u(k)&=-Kx(k).
\end{align*}

Consider a disturbance under the same control:
\begin{align*}
    u(k)=-Kx(k)+v(k)
\end{align*} 
inserting this into (\ref{eq:lssm}) yields
\begin{align*}
    x(k+1) &= (F-GK)x(k)-Gv(k)\\
    y(k) &= (C-DK)x(k)+Dv(k)
\end{align*}

Closed vs open loop: In closed loops we don't change our course based on observations, while in open loop systems we do.
% TODO: Check

\subsection{State Space Models in continuous Time}

\[\frac{d}{dt}x=f(x,u)\]
for \(x\in \R^n, u\in \R^m\). We often write \(u_t,x_t\) for \(u,x\) at time \(t\).
If \(f\) is linear we get
\begin{align*}
    \frac{d}{dt}x&=Ax+Bu\\
    y&=Cx+Du
\end{align*}

\begin{figure}[H]\label{fig:1.04}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
    \caption{Sketch 1.04}
\end{figure}

To discretize we use the \dhighlight{forward Euler method}. Given time interval \(\Delta\)
\[x(k+1)=x(k)+\Delta f(x(k),u(k))\]
so in (\ref{eq:1}) \(\cF(x,u)=x+\Delta f(x,u)\).
Using Taylor
\[x_{t+ \Delta}=x_t \Delta f(x,u)+O(\Delta^2)\]

For the linear model we get 
\(F=I+\Delta A\)
\begin{align*}
    x(k+1) &= x(k)+\Delta Ax(k)+\underbrace{\Delta B}_{\eqqcolon G}u(k)
\end{align*}

For now fix some policy \(\phi\), so \(u(k)=\phi(x(k))\):
\[x(k+1)=\cF(x(k))\]
\begin{assumption}\label{ass:1.2}
    The state space \(X\) is equal to \(\R^n\) or a closed subset of \(\R^n\).
\end{assumption}

\begin{definition}\label{def:1.3}
    An \dhighlight{equilibrium} \(x^e\) is a state at which is system is frozen:
    \[x^e=\cF(x^e).\]
\end{definition}


\begin{definition}\label{def:1.4}\marginnote{The same concept with a different sign comes up in RL under the term \dhighlight{reward}}
    Given a \dhighlight{cost function} \(C:X\to \R_+\) and a 
    policy \(\phi\) we define 
    \[J_\phi(x)=J(x)=\sum_{k=0}^\infty C(x(k)),\ x(0)=x\] 
    This is called \dhighlight{total cost} or \dhighlight{value function} of the policy \(\phi\).
\end{definition}
Given \(x^e\), we usually assume \(C(x^e)=0\). Generally, we consider a discount factor \(\gamma^k\) in front of \(C(x(k))\).

\begin{definition}\label{def:1.5}
    Denote by \(\cX(k;x_0)\) the state step \(k\) with initial condition \(x_0\) and following fixed policy \(\phi\).
    The equilibrium \(x^e\) is \dhighlight{stable in the sense of Lyapunov} if for all 
    \(\epsilon>0\exists \delta>0\) s.t. \(\Vert x_0-x^e\Vert < \delta\), then 
    \[\Vert \cX(k;x_0)-\cX(k;x^e)\Vert<\epsilon \forall k\geq 0\]
\end{definition}

\begin{figure}[H]\label{fig:1.05}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
    \caption{Sketch about Lyapunov stability}
\end{figure}

\begin{definition}\label{def:1.6}
    An equilibrium is said to be \dhighlight{asymptotically stable} if 
    \(x^e\) is stable in the sense of Lyapunov and for some \(\delta_0>0\),
    whenever \(\Vert x_0-x^e\Vert<\delta_0\), it follows
    \[\lim_{k \to\infty} \cX(k,x_0)=x^e.\]
    The set of \(x_0\) for which this holds is the \dhighlight{region of attraction} for 
    \(x^e\), An equilibrium is \dhighlight{globally asymptotically stable} if the region of attraction 
    is \(X\). 
\end{definition}
\markeol{01}

\beginlecture{02}{15.04.2025}

\begin{definition}[Lyapunov function]\label{def:1.07}

    A function \(V:X\to \R_+\) is called \dhighlight{Lyapunov function}. We frequently
    assume \(V\) is \dhighlight{inf-compact}, i.e.: it holds 
    \[\forall x^0\in X:\ \{x\in X\mid V(x)\leq V(x^0)\}\text{ is a bounded set}.\]

\end{definition}

\begin{remark}
    There is some variability in the definition of Lyapunov functions! We often assume \(V(x)\) is large if \(x\) is large.
\end{remark}

\dhighlight{Sublevel sets:} \[S_V(r)=\{x\in X \mid V(x)\leq r\}.\]
On can see with \(V\) being inf-compact \(S_V(r)\) is either
\begin{itemize}
    \item empty
    \item the whole domain \(X\) \marginnote{We usually want to avoid this}
    \item a bounded subset of \(X\). 
\end{itemize}

Usually, \(S_V(r)=X\) is impossible, a common assumption is \dhighlight{coersiveness}:
\[\lim_{\Vert x\Vert \to\infty} V(x)=\infty.\]

\begin{example}
    \begin{itemize}
        \item \(V(x)=x^2\), coercive
        \item \(V(x)=\frac{x^2}{(1+x)^2}\), not coercive, but inf-compact \(r>1: S_V(r)=\R,\ r<1: S_V(r)=[-a,a]\) with \(a=\sqrt{\frac{r}{1+r}}\)
        \item \(V(x)=e^x\) is neither
    \end{itemize}
\end{example}

\begin{lemma}\label{lem:1.08}
    Suppose that the cost function \(C\) and the value function \(J\) from definition \ref{def:1.5} are non-negative and 
    finite valued\marginnote{this is a assumption on the value function}.
    \begin{enumerate}
        \item \(J(x(k))\) is non-increasing in \(k\) and \(\lim_{k\to\infty} J(x(k))=0\) for each initial condition.
        \item In addition let \(J\) be continuous, inf-compact and vanishing only at \(x^e\). Then for each initial condition 
            \[\lim_{k\to\infty} x(k)=x^e\]
    \end{enumerate} 
\end{lemma}

\begin{proof}
    Consider \(J(x)=\sum_{k=0}^\infty c(x(k))\), then 
    \begin{align*}
        J(x) &= c(x)+\sum_{k=1}^\infty c(x(k))\\
        &=c(x)+\sum_{k=0}^\infty c(x^+(k)); \ x^+(0)=\cF(x)\\
        &=c(x)+ J(\mathcal{F}(x))
    \end{align*}
    This is the \dhighlight{dynamic programming principle} for a \dhighlight{fixed policy}.\marginnote{We are separating one step!}
    It is also called \dhighlight{Bellmann equation}.\marginnote{\\ This is the same Bellman from the curse of dimensionality!}
    For 1. from this it follows \begin{align*}
        J(x(k+1))+c(x)-J(x(k)) &= 0
    \end{align*}
    summing up from \(k=0\) up to \(N-1\)
    \begin{align*}
        J(x)=J(x(N))+\sum_{k=0}^{N-1}c(x(k))\\ \implies \text{ non-increasing}
    \end{align*}
    Taking the limit
    \begin{align*}
        =\lim_{N\to\infty}\left[J(x(N)+\sum_{k=0}^{N-1}c(x(k)))\right]=\left[\lim_{N\to\infty} J(x(N))\right]+J(x)
    \end{align*}
    using \(J(x)\) is finite gives (i).

    For 2. with \(r=J(x)\), we get \(x(k)\in S_J(k)\forall k\). Now suppose \(\{x(k_i)\}\) is a convergent subsequence
    of the trajectory with limit \(x^\infty\). Then \(J(x^\infty)=\lim_{i\to\infty}J(x(k_i))=0\) by the continuity of \(J\).
    We assumed \(J(x)=0 \iff x^e=x\implies x^\infty=x^e.\) Finally, the assumption follows, since each convergent subsequence reach the same value \(x^e\).

\end{proof}

\begin{definition}[Poisson's inequality]\label{def:1.9}\marginnote{We often assume \(\eta=0\)}
    Let \(V,c:X\to\R_+\) and \(\eta\geq 0\). Then \dhighlight{Poisson's inequality} states that 
    \[V(\mathcal{F}(x))\leq V(x)-c(x)+\eta.\]
\end{definition}


\begin{proposition}\label{prop:1.10}
    Suppose the Poisson inequality holds with \(\eta=0\). Additionally
    \(V\) shall be continuous, inf-compact and it shall have a unique minima at $x^e$. Then \(x^e\)
    is stable in the sense of Lyapunov (\dhighlight{sitsoL}).    
\end{proposition}

\begin{proof}
    \[\bigcap \{S_V(r)\mid r>V(x^e)\}=\{S_V(r)\restrict{r=V(x^e)}\}\stackrel{\text{unique minimizer}}{=}\{x^e\}.\]
    Using compactness we get: For each \(\epsilon>0\), we can find some \(r>V(x^e)\)
    and some \(\delta<\epsilon\) s.t. 
    \[\{x\in X\mid \Vert x-x^e\Vert < \delta\}\subset S_V(r)\subset \{x\in X\mid \Vert x-x^e\Vert < \epsilon\}\]
    If \(\Vert x_0-x^e\Vert<\delta\), then \(x_0\in S_v(r)\) and hence \(x(k)\in S_v(k)\)
    since \(V(x(k))\) is non-increasing. With the second inclusion we see 
    \[\Vert \mathcal{k}-x^e\Vert<\epsilon\forall k\]
    This gives sitsoL.
\end{proof}

\begin{proposition}[Comparison theorem]\label{prop:1.11}\marginnote{We don't write that explictlly, but we don't start in \(x^e\)!}
    Poisson's inequality implies 
    \begin{enumerate}
        \item For each \(N\geq 1\) and \(x=x(0)\) \[V(x(N))+\sum_{k=0}^{N-1}c(x(k))\leq V(x)+ N\eta\]
        \item If \(\eta=0\), then \(J(x)\leq V(x)\forall x\)
        \item Assume \(\eta=0\) and \(V,c\) are continuous. Suppose that \(c\) is inf-compact and vanishes only at the equilibrium \(x^e\). Then 
              \(x^e\) is globally asymptotically stable.  
    \end{enumerate}
\end{proposition}

\begin{proof}
    1. \begin{align*}
        V(x(k+1))-V(x(k))+c(x(k))\leq \eta 
    \end{align*}
    summing up from \(0\) to \(N-1\):
    \begin{align*}
        V(x(N))-V(x(0))+\sum_{k=0}^{N-1}c(x(k))\leq N\eta
    \end{align*}
    2. for \(\eta=0\)the above is \(\leq 0\), so \(\sum_{k=0}^{N-1}c(x(k))\leq V(x(0))-V(x(k))\leq V(x(0))\)
    where the LHS converges to \(J(x(0))\) for \(N\to\infty\) 

    3. Show sitsoL,  with \(\eta=0\) it follows form proposition \ref{def:1.9} that \(V(x)\geq c(x)\), which gives \(V\) is 
    also inf-compact. \marginnote{This is important!}
    \(c\) is vanishing only at \(x^e\), so \(V(x(k))\) is strictly decreasing. When \(x(k)\neq x^e\),
    implies \(V(x(k))\downarrow V(x^e)\) for each \(x(0)\). Further
    \[V(x^e)<V(x(0))\ \forall x(0)\in X\setminus\{x^e\}.\] 
    So it is a unique minimum. \(V\) has therefore the properties of proposition \ref{prop:1.10}, which gives sitsoL. 

    For global: with 1. we get \[\lim_{k\to\infty}c(x(k))=0\]
    and assumptions give us by lemma \ref{lem:1.08} that \(x(k)\to x^e\) as \(k\to\infty\).
    So, we converge from any initial condition, which gives global asymptotical stability.

\end{proof}


\begin{proposition}\label{prop:1.12}
    Suppose that \(V(\mathcal{F}(x))=V(x)-c(x)\). Further, we assume that 
    \begin{enumerate}
        \item \(J\) is continuous, inf-compact, vanishing only at \(x^e\)
        \item \(V\) is continuous
    \end{enumerate}
    Then \(J(x)=V(x)-V(x^e)\).
\end{proposition}

\begin{proof}
    As before we sum up:
    \begin{align*}
        V(x(0))+\overbrace{\sum_{k=0}^{N-1}c(x(k))}^{J(x(N-1))\stackrel{N\to\infty}{\to}J(x)}=V(x).
    \end{align*}
    Lemma \ref{lem:1.08} together with the continuity of \(V\) implies that
    \[V(x(N))\to V(x^e)\ \text{ as }N\to\infty.\]
    This gives \[V(x^e)+J(x)=V(x)\qedhere\]
\end{proof}
\markeol{02} 